{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"saaf.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"BNm6IplPkPaB","colab_type":"code","colab":{}},"cell_type":"code","source":["def saaf(narr):\n","    \n","    ## TOKENIZATION\n","    from nltk.tokenize import word_tokenize as wtk\n","    words = wtk(narr)\n","    words = [x.lower() for x in words]\n","#     print(len(words))\n","#     print(words)\n","\n","    ## REMOVING STOPWORDS AND PUNCTUATIONS\n","    from nltk.corpus import stopwords\n","    from string import punctuation\n","    custom = set(stopwords.words('english')+list(punctuation) + [\"â€™\"])\n","    words = [x for x in words if x not in custom]\n","#     print(len(words))\n","#     print(words)\n","    \n","    ## LEMMATIZATION\n","    from nltk.stem import WordNetLemmatizer as wnl\n","    lem = wnl()\n","    words = [lem.lemmatize(x) for x in words]\n","#     print(len(words))\n","#     print(words)\n","    narr = ' '.join([x for x in words])\n","    \n","    return narr"],"execution_count":0,"outputs":[]}]}